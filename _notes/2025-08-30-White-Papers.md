---
layout: post
title:  "White Papers"
date:   2025-08-30
categories:
---
<style>
	.head{
		font-size: 25px;
		color: grey;
		font-weight: bold
	}
	a {
	    color: blue
	        
	   }

	 a:hover{
	 	color: red;
	 	background-color: white
	 }
	 .des{
	 	background-color: lightgray
	 }
</style>

<span class="head">DEEP LEARNING</span>

---


1. <a href="https://arxiv.org/pdf/1706.03762">[Attention Is All You Need]</a> (Transformers) - <span class="des" >a neural network architecture that uses only attention mechanisms—abandoning recurrence and convolution—to enable fast, parallel, and state-of-the-art performance in tasks like machine translation and language modeling. This paper revolutionized AI by enabling models to efficiently capture relationships between all sequence elements, forming the backbone of today’s generative language models</span>


2. <a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">[ImageNet Classification with Deep Convolutional Neural Networks]</a> (Alexnet) - <span class="des">AlexNet is a deep convolutional neural network introduced in 2012 that won the ImageNet competition by using innovations like ReLU activation for faster training, dropout for reducing overfitting, overlapping pooling, and GPU parallelism. It drastically improved image recognition accuracy and sparked the deep learning revolution in computer vision.</span>


<span class="head">MACHINE LEARNING</span>

---